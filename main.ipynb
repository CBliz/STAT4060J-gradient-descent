{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello\n",
    "My good friend created this code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (80,) (20,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     33\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m, (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m4\u001b[39m))  \u001b[38;5;66;03m# Input data\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Noisy outputs\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Initial hyperparameters: log(sigma_s), log(sigma_n), log(diag(W))\u001b[39;00m\n\u001b[1;32m     37\u001b[0m initial_theta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1.0\u001b[39m] \u001b[38;5;241m*\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (80,) (20,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def squared_exponential_kernel(x1, x2, sigma_s, W):\n",
    "    \"\"\"Squared Exponential Kernel function.\"\"\"\n",
    "    diff = x1 - x2\n",
    "    return sigma_s * np.exp(-0.5 * diff.T @ W @ diff)\n",
    "\n",
    "def compute_kernel_matrix(X, sigma_s, W, sigma_n):\n",
    "    \"\"\"Compute the kernel matrix with added noise.\"\"\"\n",
    "    n = X.shape[0]\n",
    "    K = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            K[i, j] = squared_exponential_kernel(X[i], X[j], sigma_s, W)\n",
    "    K += sigma_n * np.eye(n)  # Add noise variance\n",
    "    return K\n",
    "\n",
    "def negative_log_likelihood(theta, X, y):\n",
    "    \"\"\"Negative log-likelihood for GP.\"\"\"\n",
    "    sigma_s, sigma_n = np.exp(theta[:2])  # Exponentiate to ensure positivity\n",
    "    W = np.diag(np.exp(theta[2:]))  # Diagonal matrix for weights\n",
    "    K = compute_kernel_matrix(X, sigma_s, W, sigma_n)\n",
    "    L = np.linalg.cholesky(K)  # Cholesky decomposition for numerical stability\n",
    "    alpha = np.linalg.solve(L.T, np.linalg.solve(L, y))\n",
    "    \n",
    "    log_likelihood = -0.5 * y.T @ alpha - np.sum(np.log(np.diagonal(L))) - (X.shape[0] / 2) * np.log(2 * np.pi)\n",
    "    return -log_likelihood  # Return negative for minimization\n",
    "\n",
    "# Example usage\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.uniform(-5, 5, (20, 1))  # Input data\n",
    "y = np.sin(X).flatten() + 0.1 * np.random.randn(X.shape[0])  # Noisy outputs\n",
    "\n",
    "# Initial hyperparameters: log(sigma_s), log(sigma_n), log(diag(W))\n",
    "initial_theta = np.log([1.0, 0.1] + [1.0] * X.shape[1])\n",
    "\n",
    "# Minimize negative log-likelihood\n",
    "result = minimize(negative_log_likelihood, initial_theta, args=(X, y), method=\"L-BFGS-B\")\n",
    "\n",
    "# Extract optimal hyperparameters\n",
    "opt_theta = result.x\n",
    "sigma_s_opt, sigma_n_opt = np.exp(opt_theta[:2])\n",
    "W_opt = np.diag(np.exp(opt_theta[2:]))\n",
    "print(\"Optimal Hyperparameters:\")\n",
    "print(f\"sigma_s: {sigma_s_opt}, sigma_n: {sigma_n_opt}, W: {W_opt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
